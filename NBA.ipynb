{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge discovery project\n",
    "## NBA 2021/2022 dataset - https://www.kaggle.com/vivovinco/nba-player-stats\n",
    "### Nina Masaryková a Marek Štrba\n",
    "March 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"2021-2022_NBA_Player_Stats.csv\"\n",
    "df = pd.read_csv(filename,index_col=0, encoding = \"ISO-8859-1\",  sep=';')\n",
    "df.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Player\"] == \"Nikola Joki?\", \"Player\"] = 'Nikola Jokic'\n",
    "df.loc[df[\"Player\"] == \"Luka Don?i?\", \"Player\"] = 'Luka Doncic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding ALLSTAR collumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_star = [0]*734"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ALLSTAR'] = all_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Player'].isin(['Trae Young', 'DeMar DeRozan', 'Joel Embiid', 'Kevin Durant', 'Giannis Antetokounmpo', 'LaMelo Ball', \n",
    "'Darius Garland', 'James Harden', 'Zach LaVine', 'Fred VanVleet', 'Jimmy Butler', 'Khris Middleton', 'Jayson Tatum', 'Jarrett Allen',\n",
    "'Stephen Curry', 'Ja Morant', 'Nikola Jokic', 'LeBron James', 'Andrew Wiggins', 'Devin Booker', 'Luka Doncic', 'Donovan Mitchell', \n",
    "'Dejounte Murray', 'Chris Paul', 'Draymond Green', 'Rudy Gobert', 'Karl-Anthony Towns']), \"ALLSTAR\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Player'].isin(['Trae Young', 'DeMar DeRozan', 'Joel Embiid', 'Kevin Durant', 'Giannis Antetokounmpo', 'LaMelo Ball', \n",
    "'Darius Garland', 'James Harden', 'Zach LaVine', 'Fred VanVleet', 'Jimmy Butler', 'Khris Middleton', 'Jayson Tatum', 'Jarrett Allen',\n",
    "'Stephen Curry', 'Ja Morant', 'Nikola Jokic', 'LeBron James', 'Andrew Wiggins', 'Devin Booker', 'Luka Doncic', 'Donovan Mitchell', \n",
    "'Dejounte Murray', 'Chris Paul', 'Draymond Green', 'Rudy Gobert', 'Karl-Anthony Towns'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Player'].isin(['Klay Thompson'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with traded players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups=df.duplicated()\n",
    "print(df[dups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradedPlayers = df[df.duplicated(['Player'])]\n",
    "print(tradedPlayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tradedPlayers[tradedPlayers['Player'] == 'Nickeil Alexander-Walker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Player'] == 'Nickeil Alexander-Walker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Tm'] == 'TOT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['Player'])\n",
    "df[df['Tm'] == 'TOT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the players which played less than 10 games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['G']<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['G'] < 10].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset contains total of %d missing values\"%int(df.shape[0] - df.dropna().shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "#### Basic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,12))\n",
    "sns.heatmap(df.corr(), ax=ax, annot=True, fmt=\".1f\")\n",
    "plt.savefig('heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis by attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_AS = df[df['ALLSTAR'] == 0]\n",
    "a_stars = df[df['ALLSTAR'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr(attribute): \n",
    "    return df[attribute].quantile(0.75) - df[attribute].quantile(0.25) \n",
    "\n",
    "def outliers(attribute):\n",
    "    iqrange = iqr(attribute)\n",
    "    lower_bound = df[attribute].quantile(0.25) -(1.5 * iqrange)\n",
    "    upper_bound = df[attribute].quantile(0.75) +(1.5 * iqrange)\n",
    "    return df[(df[attribute] > upper_bound) | (df[attribute] < lower_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_box_color(bp, color):\n",
    "    plt.setp(bp['boxes'], color=color)\n",
    "    plt.setp(bp['whiskers'], color=color)\n",
    "    plt.setp(bp['caps'], color=color)\n",
    "    plt.setp(bp['medians'], color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('Age', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of outliers for age is: \",len(outliers('Age')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 42, 2)\n",
    "\n",
    "plt.hist(not_AS['Age'], bins, alpha=0.5, label='Not AS')\n",
    "plt.hist(a_stars['Age'], bins, alpha=0.5, label='AS')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "ticks = [\"Age\"]\n",
    "\n",
    "bpna = plt.boxplot(not_AS['Age'], positions=[0],widths=0.6)\n",
    "bpas = plt.boxplot(a_stars['Age'], positions=[1],widths=0.6)\n",
    "\n",
    "set_box_color(bpna, '#2C7BB6')\n",
    "set_box_color(bpas, '#e6ac0e') \n",
    "\n",
    "plt.plot([], c='#2C7BB6', label='Not All Stars')\n",
    "plt.plot([], c='#e6ac0e', label='All Stars')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
    "plt.xlim(-2, 6)\n",
    "plt.ylim(0, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(np.arange(18, 42, 1))\n",
    "plt.yticks(np.arange(0, 100, 10))\n",
    "df['Age'].hist(bins=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(df.Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('G', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of outliers for games played is: \",len(outliers('G')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['G'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 66, 2)\n",
    "\n",
    "plt.hist(not_AS['G'], bins, alpha=0.5, label='Not AS')\n",
    "plt.hist(a_stars['G'], bins, alpha=0.5, label='AS')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Games Played')\n",
    "plt.savefig('G-hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "ticks = [\"Games Played\"]\n",
    "\n",
    "bpna = plt.boxplot(not_AS['G'], positions=[0],widths=0.6)\n",
    "bpas = plt.boxplot(a_stars['G'], positions=[1],widths=0.6)\n",
    "\n",
    "set_box_color(bpna, '#2C7BB6')\n",
    "set_box_color(bpas, '#e6ac0e') \n",
    "\n",
    "plt.plot([], c='#2C7BB6', label='Not All Stars')\n",
    "plt.plot([], c='#e6ac0e', label='All Stars')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
    "plt.xlim(-2, 6)\n",
    "plt.ylim(0, 70)\n",
    "plt.savefig('G-box.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(np.arange(0, 60, 2))\n",
    "plt.yticks(np.arange(0, 100, 10))\n",
    "df['G'].hist(bins=60, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(df.G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minutes played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('MP', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of outliers for minutes played is: \",len(outliers('MP')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MP'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 60, 2)\n",
    "\n",
    "plt.hist(not_AS['MP'], bins, alpha=0.5, label='Not AS')\n",
    "plt.hist(a_stars['MP'], bins, alpha=0.5, label='AS')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Minutes Played')\n",
    "plt.savefig('MP-hist.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "ticks = [\"Minutes Played\"]\n",
    "\n",
    "bpna = plt.boxplot(not_AS['MP'], positions=[0],widths=0.6)\n",
    "bpas = plt.boxplot(a_stars['MP'], positions=[1],widths=0.6)\n",
    "\n",
    "set_box_color(bpna, '#2C7BB6')\n",
    "set_box_color(bpas, '#e6ac0e') \n",
    "\n",
    "plt.plot([], c='#2C7BB6', label='Not All Stars')\n",
    "plt.plot([], c='#e6ac0e', label='All Stars')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
    "plt.xlim(-2, 6)\n",
    "plt.ylim(0, 50)\n",
    "plt.savefig('MP-box.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(np.arange(0, 40, 2))\n",
    "plt.yticks(np.arange(0, 40, 10))\n",
    "df['MP'].hist(bins=60, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(df.MP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Points per game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('PTS', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of outliers for points scored is: \",len(outliers('PTS')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PTS'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 40, 2)\n",
    "\n",
    "plt.hist(not_AS['PTS'], bins, alpha=0.5, label='Not AS')\n",
    "plt.hist(a_stars['PTS'], bins, alpha=0.5, label='AS')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Points per game')\n",
    "plt.savefig('PTS-hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "ticks = [\"Points per game\"]\n",
    "\n",
    "bpna = plt.boxplot(not_AS['PTS'], positions=[0],widths=0.6)\n",
    "bpas = plt.boxplot(a_stars['PTS'], positions=[1],widths=0.6)\n",
    "\n",
    "set_box_color(bpna, '#2C7BB6')\n",
    "set_box_color(bpas, '#e6ac0e') \n",
    "\n",
    "plt.plot([], c='#2C7BB6', label='Not All Stars')\n",
    "plt.plot([], c='#e6ac0e', label='All Stars')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
    "plt.xlim(-2, 6)\n",
    "plt.ylim(0, 40)\n",
    "plt.savefig('PTS-box.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(np.arange(0, 35, 2))\n",
    "plt.yticks(np.arange(0, 40, 10))\n",
    "df['PTS'].hist(bins=60, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.shapiro(df.PTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shooting efficiency eFG%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('eFG%', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of outliers for shooting efficiency is: \",len(outliers('eFG%')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eFG%'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.0, 1.0, 0.05)\n",
    "\n",
    "plt.hist(not_AS['eFG%'], bins, alpha=0.5, label='Not AS')\n",
    "plt.hist(a_stars['eFG%'], bins, alpha=0.5, label='AS')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Shooting efficiency')\n",
    "plt.savefig('Efg-hist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "ticks = [\"Shooting efficiency\"]\n",
    "\n",
    "bpna = plt.boxplot(not_AS['eFG%'], positions=[0],widths=0.6)\n",
    "bpas = plt.boxplot(a_stars['eFG%'], positions=[1],widths=0.6)\n",
    "\n",
    "set_box_color(bpna, '#2C7BB6')\n",
    "set_box_color(bpas, '#e6ac0e') \n",
    "\n",
    "plt.plot([], c='#2C7BB6', label='Not All Stars')\n",
    "plt.plot([], c='#e6ac0e', label='All Stars')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
    "plt.xlim(-2, 6)\n",
    "plt.ylim(0., 1.5)\n",
    "plt.savefig('Efg-box.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting PTS - points per game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further analysis of the attributes and their distributions and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df['PTS'], dist=\"norm\", plot=pylab)\n",
    "plt.title('PTS - Probability plot')\n",
    "plt.savefig('PTS-qq.png')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_shapiro = stats.shapiro(df.PTS)\n",
    "tov_shapiro = stats.shapiro(df.TOV)\n",
    "stl_shapiro = stats.shapiro(df.STL)\n",
    "pf_shapiro = stats.shapiro(df.PF)\n",
    "mp_shapiro = stats.shapiro(df.MP)\n",
    "ft_shapiro = stats.shapiro(df.FT)\n",
    "ast_shapiro = stats.shapiro(df.AST)\n",
    "\n",
    "print(\"Shapiro PTS: Statistics: \", pts_shapiro.statistic , \" P-values\", format( pts_shapiro.pvalue, '.28f'))\n",
    "print(\"Shapiro TOV: Statistics: \", tov_shapiro.statistic , \" P-values\", format( tov_shapiro.pvalue, '.28f'))\n",
    "print(\"Shapiro STL: Statistics: \", stl_shapiro.statistic , \" P-values\", format( stl_shapiro.pvalue, '.28f'))\n",
    "print(\"Shapiro PF: Statistics: \", pf_shapiro.statistic , \" P-values\", format( pf_shapiro.pvalue, '.28f'))\n",
    "print(\"Shapiro MP: Statistics: \", mp_shapiro.statistic , \" P-values\", format( mp_shapiro.pvalue, '.28f'))\n",
    "print(\"Shapiro FT: Statistics: \", ft_shapiro.statistic , \" P-values\", format( ft_shapiro.pvalue, '.28f'))\n",
    "print(\"Shapiro AST: Statistics: \", ast_shapiro.statistic , \" P-values\", format( ast_shapiro.pvalue, '.28f'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerpuffgirls(data, method):\n",
    "    power = PowerTransformer(method=method, standardize=True) \n",
    "    data_trans = power.fit_transform(data.copy())\n",
    "    return data_trans\n",
    "\n",
    "def best_transform(column,data):\n",
    "    pvalues=dict()\n",
    "\n",
    "    pvalues['data']=[stats.shapiro(data[column])[1],data]\n",
    "       \n",
    "    data_y=data.copy()\n",
    "    data_y[column]=powerpuffgirls(data_y[[column]],\"yeo-johnson\")\n",
    "    pvalues['data_y']=[stats.shapiro( data_y[column])[1],data_y]\n",
    "    \n",
    "    \n",
    "    if (any(data[column]<=0)==False):\n",
    "        data_b=data.copy()\n",
    "        data_b[column]=powerpuffgirls(data_b[[column]],\"box-cox\")\n",
    "        pvalues['data_b']=[stats.shapiro( data_b[column])[1],data_b]\n",
    "    \n",
    "    sorted_pvalues=sorted(pvalues.items(),key=operator.itemgetter(0))\n",
    "    \n",
    "    return(sorted_pvalues[-1][1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['PTS', 'AST', 'TOV', 'FT', 'MP', 'STL','PF']\n",
    "\n",
    "for col in col_list:\n",
    "  print('------------')\n",
    "  print(col)\n",
    "  transformed = best_transform(col, df)\n",
    "  t_shapiro = stats.shapiro(transformed[col])\n",
    "  print(\"Shapiro \", col, \" : Statistics: \", t_shapiro.statistic , \" P-values\", format( t_shapiro.pvalue, '.28f'))\n",
    "  \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personal fouls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"PTS\", y=\"PF\", data=df)\n",
    "plt.title('PF scatter distribution')\n",
    "plt.savefig('PF-scat.png')\n",
    "print(\"Pearson correlation: %.3f\" % df['PTS'].corr(df['PF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df['PF'], dist=\"norm\", plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn overs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"PTS\", y=\"TOV\", data=df)\n",
    "print(\"Pearson correlation: %.3f\" % df['PTS'].corr(df['TOV']))\n",
    "plt.savefig('PTS-TOV-corr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df['TOV'], dist=\"norm\", plot=pylab)\n",
    "plt.title('TOV - Probability plot')\n",
    "plt.savefig('TOV-qq.png')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minutes played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"PTS\", y=\"MP\", data=df)\n",
    "print(\"Pearson correlation: %.3f\" % df['PTS'].corr(df['MP']))\n",
    "plt.savefig('PTS-MP-corr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df['MP'], dist=\"norm\", plot=pylab)\n",
    "plt.title('MP - Probability plot')\n",
    "plt.savefig('MP-qq.png')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Free throws made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"PTS\", y=\"FT\", data=df)\n",
    "print(\"Pearson correlation: %.3f\" % df['PTS'].corr(df['FT']))\n",
    "plt.savefig('PTS-FT-corr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df['FT'], dist=\"norm\", plot=pylab)\n",
    "plt.title('FT - Probability plot')\n",
    "plt.savefig('FT-qq.png')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"PTS\", y=\"STL\", data=df)\n",
    "plt.title('STL scatter distribution')\n",
    "plt.savefig('STL-scat.png')\n",
    "print(\"Pearson correlation: %.3f\" % df['PTS'].corr(df['STL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df['STL'], dist=\"norm\", plot=pylab)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"PTS\", y=\"AST\", data=df)\n",
    "print(\"Pearson correlation: %.3f\" % df['PTS'].corr(df['AST']))\n",
    "plt.savefig('PTS-AST-corr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df['AST'], dist=\"norm\", plot=pylab)\n",
    "plt.title('AST - Probability plot')\n",
    "plt.savefig('AST-qq.png')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the predictors to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['PTS', 'AST', 'TOV', 'FT', 'MP']]\n",
    "data.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = pd.plotting.scatter_matrix(data, alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('scatter_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction made while using all attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resid_df(y_test, predict):\n",
    "  reses_abs = []\n",
    "  reses = []\n",
    "  for i in range(0,np.size(predict)):\n",
    "    reses_abs.append(abs(y_test[i] - predict[i]))\n",
    "  res_dict = {'Actual':y_test, 'Predicted':predict, 'Residual (ABS)':reses_abs, 'Reses':reses}\n",
    "  res_dict_df = pd.DataFrame(data=res_dict)\n",
    "  return res_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['AST', 'TOV', 'FT', 'MP']], data['PTS'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedPoints = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_rmse = np.sqrt(mean_squared_error(y_test, predictedPoints))\n",
    "print('RMSE:',poly_reg_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, predictedPoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(predictedPoints, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "plt.savefig('lin_points.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(predictedPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictedPoints<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PTS'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[['TOV', 'FT', 'MP', 'AST']], data['PTS']\n",
    "regrCS = linear_model.LinearRegression()\n",
    "scores = cross_val_score(regrCS, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "scores = [x * -1 for x in scores]\n",
    "\n",
    "print(scores)\n",
    "print('RMSE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[['AST', 'TOV', 'FT', 'MP']], data['PTS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "poly_reg = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "pol_reg = linear_model.LinearRegression()\n",
    "pol_reg.fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_all_pred = pol_reg.predict(poly_reg.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_rmse = np.sqrt(mean_squared_error(y_test, poly_all_pred))\n",
    "print('RMSE:',poly_reg_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, poly_all_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(poly_all_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "plt.savefig('poly_points.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[['TOV', 'FT', 'MP', 'AST']], data['PTS']\n",
    "poly_reg = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "pol_reg_cs = linear_model.LinearRegression()\n",
    "scores = cross_val_score(pol_reg_cs, X_poly, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "scores = [x * -1 for x in scores]\n",
    "\n",
    "print(scores)\n",
    "print('RMSE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction after removing AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['TOV', 'FT', 'MP']], data['PTS'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedPoints = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_rmse = np.sqrt(mean_squared_error(y_test, predictedPoints))\n",
    "print('RMSE:',poly_reg_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, predictedPoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(predictedPoints, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "plt.savefig('lin_points_noassist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(predictedPoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictedPoints<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PTS'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[['TOV', 'FT', 'MP']], data['PTS']\n",
    "regrCS = linear_model.LinearRegression()\n",
    "scores = cross_val_score(regrCS, X, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "scores = [x * -1 for x in scores]\n",
    "\n",
    "print(scores)\n",
    "print('RMSE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[['TOV', 'FT', 'MP']], data['PTS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "poly_reg = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "pol_reg = linear_model.LinearRegression()\n",
    "pol_reg.fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_all_pred = pol_reg.predict(poly_reg.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg_rmse = np.sqrt(mean_squared_error(y_test, poly_all_pred))\n",
    "print('RMSE:',poly_reg_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, poly_all_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(poly_all_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "plt.savefig('poly_points_noassist.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[['TOV', 'FT', 'MP']], data['PTS']\n",
    "poly_reg = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "pol_reg_cs = linear_model.LinearRegression()\n",
    "scores = cross_val_score(pol_reg_cs, X_poly, y, cv=5, scoring='neg_root_mean_squared_error')\n",
    "scores = [x * -1 for x in scores]\n",
    "\n",
    "print(scores)\n",
    "print('RMSE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing legends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[['TOV', 'FT', 'MP']], data['PTS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "poly_reg = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "pol_reg = linear_model.LinearRegression()\n",
    "pol_reg.fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legends = {'TOV':[3.1, 3.3, 3.1, 3.3, 2.6],'FT':[8.8, 4.6, 8.7, 7.6, 7.7], 'MP':[40.4, 34.2, 41.0, 42.5, 39.4], 'PTS':[35.0, 30.1, 35.4, 31.4, 32.1]}\n",
    "legends_df = pd.DataFrame(data=legends)\n",
    "X_leg = legends_df[['TOV', 'FT', 'MP']]\n",
    "Y_leg = legends_df['PTS']\n",
    "legends_pred = pol_reg.predict(poly_reg.fit_transform(X_leg))\n",
    "\n",
    "leg_rmse = np.sqrt(mean_squared_error(Y_leg, legends_pred))\n",
    "print('RMSE:',leg_rmse)\n",
    "print('MSE:',mean_squared_error(Y_leg, legends_pred))\n",
    "\n",
    "print('True:', Y_leg)\n",
    "print('Predictions:', legends_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legends_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single attribute predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['MP']]\n",
    "Y = data['PTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color = \"red\")\n",
    "plt.plot(X_train, regr.predict(X_train), color = \"green\")\n",
    "plt.title(\"Points Based on Minutes Played (Linear - Train)\")\n",
    "plt.xlabel(\"Minutes Played\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedPoints = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color = \"red\")\n",
    "plt.plot(X_test, regr.predict(X_test), color = \"green\")\n",
    "plt.title(\"Points Based on Minutes Played (Linear - Test)\")\n",
    "plt.xlabel(\"Minutes Played\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.savefig('minutes_lin_points.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_min_rmse = np.sqrt(mean_squared_error(y_test, predictedPoints))\n",
    "print('RMSE:',lin_min_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, predictedPoints) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(predictedPoints, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg = PolynomialFeatures(degree=3)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "pol_reg = linear_model.LinearRegression()\n",
    "pol_reg.fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_min_pred = pol_reg.predict(poly_reg.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_min_rmse = np.sqrt(mean_squared_error(y_test, poly_min_pred))\n",
    "print('RMSE:',poly_min_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, poly_min_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.scatter(X_test, poly_min_pred, c='red')\n",
    "plt.title(\"Points Based on Minutes Played (Polynomial - Test)\")\n",
    "plt.xlabel(\"Minutes Played\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.savefig('minutes_poly_points.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(poly_min_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)\n",
    "plt.savefig('minutes_poly_points_acc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['AST']]\n",
    "Y = data['PTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color = \"red\")\n",
    "plt.plot(X_train, regr.predict(X_train), color = \"green\")\n",
    "plt.title(\"Points Based on Assists (Linear - Train)\")\n",
    "plt.xlabel(\"Assists\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedPoints = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color = \"red\")\n",
    "plt.plot(X_test, regr.predict(X_test), color = \"green\")\n",
    "plt.title(\"Points Based on Assists (Linear - Test)\")\n",
    "plt.xlabel(\"Assists\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.savefig('ast_lin_points.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_ast_rmse = np.sqrt(mean_squared_error(y_test, predictedPoints))\n",
    "print('RMSE:',lin_ast_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, predictedPoints) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(predictedPoints, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg = PolynomialFeatures(degree=3)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "pol_reg = linear_model.LinearRegression()\n",
    "pol_reg.fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_ast_pred = pol_reg.predict(poly_reg.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_ast_rmse = np.sqrt(mean_squared_error(y_test, poly_ast_pred))\n",
    "print('RMSE:',poly_ast_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, poly_ast_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.scatter(X_test, poly_ast_pred, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(poly_ast_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['TOV']]\n",
    "Y = data['PTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color = \"red\")\n",
    "plt.plot(X_train, regr.predict(X_train), color = \"green\")\n",
    "plt.title(\"Points Based on Turnovers (Linear - Train)\")\n",
    "plt.xlabel(\"Turnovers\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedPoints = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color = \"red\")\n",
    "plt.plot(X_test, regr.predict(X_test), color = \"green\")\n",
    "plt.title(\"Points Based on Turnovers (Linear - Test)\")\n",
    "plt.xlabel(\"Turnovers\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_ast_rmse = np.sqrt(mean_squared_error(y_test, predictedPoints))\n",
    "print('RMSE:',lin_ast_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, predictedPoints) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(predictedPoints, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg = PolynomialFeatures(degree=6)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "pol_reg = linear_model.LinearRegression()\n",
    "pol_reg.fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_tov_pred = pol_reg.predict(poly_reg.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_tov_rmse = np.sqrt(mean_squared_error(y_test, poly_tov_pred))\n",
    "print('RMSE:',poly_tov_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, poly_tov_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.scatter(X_test, poly_tov_pred, c='red')\n",
    "plt.title(\"Points Based on Turnovers (Polynomial - Test)\")\n",
    "plt.xlabel(\"Turnovers\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.savefig('tov_poly_points.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(poly_tov_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['FT']]\n",
    "Y = data['PTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color = \"red\")\n",
    "plt.plot(X_train, regr.predict(X_train), color = \"green\")\n",
    "plt.title(\"Points Based on Free throws (Linear - Train)\")\n",
    "plt.xlabel(\"Free throws\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedPoints = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color = \"red\")\n",
    "plt.plot(X_test, regr.predict(X_test), color = \"green\")\n",
    "plt.title(\"Points Based on Free throws (Linear - Test)\")\n",
    "plt.xlabel(\"Free throws\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_ast_rmse = np.sqrt(mean_squared_error(y_test, predictedPoints))\n",
    "print('RMSE:',lin_ast_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, predictedPoints) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(predictedPoints, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reg = PolynomialFeatures(degree=2)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "pol_reg = linear_model.LinearRegression()\n",
    "pol_reg.fit(X_poly, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_ft_pred = pol_reg.predict(poly_reg.fit_transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_ft_rmse = np.sqrt(mean_squared_error(y_test, poly_ft_pred))\n",
    "print('RMSE:',poly_ft_rmse)\n",
    "print('MSE:',mean_squared_error(y_test, poly_ft_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.scatter(X_test, poly_ft_pred, c='red')\n",
    "plt.title(\"Points Based on Free throws (Polynomial - Test)\")\n",
    "plt.xlabel(\"Free throws\")\n",
    "plt.ylabel(\"Points\")\n",
    "plt.savefig('ft_poly_points.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.distplot(y_test, hist=False, color=\"r\", label=\"Actual Value\")\n",
    "sns.distplot(poly_ft_pred, hist=False, color=\"b\", label=\"Fitted Values\" , ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL STAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prediction(predictions_prob, predictions, y_test):\n",
    "  pred_class_1 = []\n",
    "  pred_class_2 = []\n",
    "  for pred in predictions_prob:\n",
    "    pred_class_1.append(pred[0])\n",
    "    pred_class_2.append(pred[1])\n",
    "  pred_dict = {'N_ALL':pred_class_1, 'ALL':pred_class_2, 'Predicted class':predictions, 'Actual class':y_test}\n",
    "  pred_dict_df = pd.DataFrame(data=pred_dict)\n",
    "  return pred_dict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(predictions, y_test, label, model):\n",
    "  cf_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "  ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "  title = 'ALL star based on ' + label + ' Confusion Matrix\\n\\n'\n",
    "  file_name = 'confusion_'+ label+'_'+ model+'.png'\n",
    "  ax.set_title(title)\n",
    "  ax.set_xlabel('\\nPredicted Values')\n",
    "  ax.set_ylabel('Actual Values ')\n",
    "\n",
    "  ## Ticket labels - List must be in alphabetical order\n",
    "  ax.xaxis.set_ticklabels(['Not All Star','All Star'])\n",
    "  ax.yaxis.set_ticklabels(['Not All Star','All Star'])\n",
    "  plt.savefig(file_name)\n",
    "  ## Display the visualization of the Confusion Matrix.\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['N_ALL', 'ALL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PTS']]\n",
    "Y = df['ALLSTAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegrPTS = LogisticRegression()\n",
    "logisticRegrPTS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = logisticRegrPTS.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegrPTS.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_prediction(predictions_prob, predictions, y_test)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_rows', None)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(predictions, y_test, 'Points', 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logisticRegrPTS.predict_proba(X_test)[::,1]\n",
    "fprPTS, tprPTS, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "aucPTS = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fprPTS,tprPTS,label=\"AUC=\"+str(aucPTS))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PTS']]\n",
    "Y = df['ALLSTAR']\n",
    "\n",
    "cross_logisticRegrPTS = LogisticRegression()\n",
    "scores = cross_val_score(cross_logisticRegrPTS, X, Y)\n",
    "print(scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['G']]\n",
    "Y = df['ALLSTAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegrGS = LogisticRegression()\n",
    "logisticRegrGS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = logisticRegrGS.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegrGS.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_prediction(predictions_prob, predictions, y_test)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_rows', None)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(predictions, y_test, 'Games_Played', 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logisticRegrGS.predict_proba(X_test)[::,1]\n",
    "fprGS, tprGS, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "aucGS = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fprGS,tprGS,label=\"AUC=\"+str(aucGS))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['MP']]\n",
    "Y = df['ALLSTAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegrMP = LogisticRegression()\n",
    "logisticRegrMP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = logisticRegrMP.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegrMP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_prediction(predictions_prob, predictions, y_test)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_rows', None)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(predictions, y_test, 'Minutes_Played', 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logisticRegrMP.predict_proba(X_test)[::,1]\n",
    "fprMP, tprMP, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "aucMP = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fprMP,tprMP,label=\"AUC=\"+str(aucMP))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PTS', 'G', 'MP']]\n",
    "Y = df['ALLSTAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegrALL = LogisticRegression()\n",
    "logisticRegrALL.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = logisticRegrALL.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegrALL.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_prediction(predictions_prob, predictions, y_test)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_rows', None)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(predictions, y_test, 'All', 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logisticRegrALL.predict_proba(X_test)[::,1]\n",
    "fprALL, tprALL, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "aucALL = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fprALL,tprALL,label=\"AUC=\"+str(aucALL))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[['PTS', 'G', 'MP']]\n",
    "Y = df['ALLSTAR']\n",
    "\n",
    "cross_logisticRegrALL = LogisticRegression()\n",
    "scores = cross_val_score(cross_logisticRegrALL, X, Y)\n",
    "print(scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PTS + MP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PTS', 'MP']]\n",
    "Y = df['ALLSTAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegrPMP = LogisticRegression()\n",
    "logisticRegrPMP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = logisticRegrPMP.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegrPMP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_prediction(predictions_prob, predictions, y_test)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_rows', None)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(predictions, y_test, 'Points_Minutes', 'logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logisticRegrPMP.predict_proba(X_test)[::,1]\n",
    "fprPMP, tprPMP, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "aucPMP = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fprPMP,tprPMP,label=\"AUC=\"+str(aucPMP))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All logistic curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fprPMP,tprPMP,label=\"AUC_PMP=\"+str(aucPMP))\n",
    "plt.plot(fprPTS,tprPTS,label=\"AUC_PTS=\"+str(aucPTS))\n",
    "plt.plot(fprGS,tprGS,label=\"AUC_Games=\"+str(aucGS))\n",
    "plt.plot(fprMP,tprMP,label=\"AUC_MP=\"+str(aucMP))\n",
    "plt.plot(fprALL,tprALL,label=\"AUC_ALL=\"+str(aucALL))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC curves logistic regression')\n",
    "plt.legend(loc=4)\n",
    "plt.savefig('ROC_logistic.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'sigmoid', 'rbf']\n",
    "target_names = ['N_ALL', 'ALL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_kernels(X_train, y_train, X_test, y_test):\n",
    "  for krnl in kernels:\n",
    "    svcclassifier = SVC(kernel=krnl)\n",
    "    svcclassifier.fit(X_train,y_train)\n",
    "    predictions = svcclassifier.predict(X_test)\n",
    "    print('Kernel: ', krnl)\n",
    "    print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PTS']]\n",
    "Y = df['ALLSTAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kernels(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PTS']]\n",
    "Y = df['ALLSTAR']\n",
    "\n",
    "cross_SVM_RBF_PTS = SVC(kernel='rbf')\n",
    "RBF_scores = cross_val_score(cross_SVM_RBF_PTS, X, Y)\n",
    "\n",
    "cross_SVM_LIN_PTS = SVC(kernel='linear')\n",
    "lin_scores = cross_val_score(cross_SVM_LIN_PTS, X, Y)\n",
    "\n",
    "print('--------------')\n",
    "print('RBF')\n",
    "print(RBF_scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(RBF_scores), std(RBF_scores)))\n",
    "print('--------------')\n",
    "print('Linear')\n",
    "print(lin_scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(lin_scores), std(lin_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "najlepsie RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcclassifierPTS = SVC(kernel='rbf', probability=True)\n",
    "svcclassifierPTS.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = svcclassifierPTS.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svcclassifierPTS.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_prediction(predictions_prob, predictions, y_test)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_rows', None)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(predictions, y_test, 'Points', 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprPTS_SVM, tprPTS_SVM, _ = metrics.roc_curve(y_test,  predictions_prob[::,1])\n",
    "aucPTS_SVM = metrics.roc_auc_score(y_test, predictions_prob[::,1])\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fprPTS_SVM,tprPTS_SVM,label=\"AUC=\"+str(aucPTS_SVM))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['G']]\n",
    "Y = df['ALLSTAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kernels(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "najlepsie RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcclassifierGS = SVC(kernel='rbf', probability=True)\n",
    "svcclassifierGS.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = svcclassifierGS.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svcclassifierGS.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_prediction(predictions_prob, predictions, y_test)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_rows', None)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(predictions, y_test, 'Games_Played', 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprGS_SVM, tprGS_SVM, _ = metrics.roc_curve(y_test,  predictions_prob[::,1])\n",
    "aucGS_SVM = metrics.roc_auc_score(y_test, predictions_prob[::,1])\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fprGS_SVM,tprGS_SVM,label=\"AUC=\"+str(aucGS_SVM))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['MP']]\n",
    "Y = df['ALLSTAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kernels(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "najlepsie RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcclassifierMP = SVC(kernel='rbf', probability=True)\n",
    "svcclassifierMP.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = svcclassifierMP.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svcclassifierMP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_prediction(predictions_prob, predictions, y_test)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_rows', None)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(predictions, y_test, 'Minutes_Played', 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprMP_SVM, tprMP_SVM, _ = metrics.roc_curve(y_test,  predictions_prob[::,1])\n",
    "aucMP_SVM = metrics.roc_auc_score(y_test, predictions_prob[::,1])\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fprMP_SVM,tprMP_SVM,label=\"AUC=\"+str(aucMP_SVM))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PTS','G','MP']]\n",
    "Y = df['ALLSTAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kernels(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PTS','G','MP']]\n",
    "Y = df['ALLSTAR']\n",
    "\n",
    "cross_SVM_RBF_ALL = SVC(kernel='rbf')\n",
    "RBF_scores = cross_val_score(cross_SVM_RBF_ALL, X, Y)\n",
    "\n",
    "cross_SVM_LIN_ALL = SVC(kernel='linear')\n",
    "lin_scores = cross_val_score(cross_SVM_LIN_ALL, X, Y)\n",
    "\n",
    "print('--------------')\n",
    "print('RBF')\n",
    "print(RBF_scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(RBF_scores), std(RBF_scores)))\n",
    "print('--------------')\n",
    "print('Linear')\n",
    "print(lin_scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(lin_scores), std(lin_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "najlepsie linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcclassifierALL = SVC(kernel='linear', probability=True)\n",
    "svcclassifierALL.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = svcclassifierALL.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svcclassifierALL.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_prediction(predictions_prob, predictions, y_test)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_rows', None)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(predictions, y_test, 'All', 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprALL_SVM, tprALL_SVM, _ = metrics.roc_curve(y_test,  predictions_prob[::,1])\n",
    "aucALL_SVM = metrics.roc_auc_score(y_test, predictions_prob[::,1])\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fprALL_SVM,tprALL_SVM,label=\"AUC=\"+str(aucALL_SVM))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PTS + Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PTS','MP']]\n",
    "Y = df['ALLSTAR']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kernels(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['PTS','MP']]\n",
    "Y = df['ALLSTAR']\n",
    "\n",
    "cross_SVM_RBF_PMP = SVC(kernel='rbf')\n",
    "RBF_scores = cross_val_score(cross_SVM_RBF_PMP, X, Y)\n",
    "\n",
    "cross_SVM_LIN_PMP = SVC(kernel='linear')\n",
    "lin_scores = cross_val_score(cross_SVM_LIN_PMP, X, Y)\n",
    "\n",
    "print('--------------')\n",
    "print('RBF')\n",
    "print(RBF_scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(RBF_scores), std(RBF_scores)))\n",
    "print('--------------')\n",
    "print('Linear')\n",
    "print(lin_scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(lin_scores), std(lin_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "najlepsie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcclassifierPMP = SVC(kernel='rbf', probability=True)\n",
    "svcclassifierPMP.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = svcclassifierPMP.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svcclassifierPMP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = class_prediction(predictions_prob, predictions, y_test)\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "pd.set_option('display.max_rows', None)\n",
    "class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(predictions, y_test, 'PMP', 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprPMP_SVM, tprPMP_SVM, _ = metrics.roc_curve(y_test,  predictions_prob[::,1])\n",
    "aucPMP_SVM = metrics.roc_auc_score(y_test, predictions_prob[::,1])\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fprPMP_SVM,tprPMP_SVM,label=\"AUC=\"+str(aucPMP_SVM))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All SVM curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fprPTS_SVM,tprPTS_SVM,label=\"AUC_PTS_SVM=\"+str(aucPTS_SVM))\n",
    "plt.plot(fprGS_SVM,tprGS_SVM,label=\"AUC_Games_SVM=\"+str(aucGS_SVM))\n",
    "plt.plot(fprMP_SVM,tprMP_SVM,label=\"AUC_MP_SVM=\"+str(aucMP_SVM))\n",
    "plt.plot(fprALL_SVM,tprALL_SVM,label=\"AUC_ALL_SVM=\"+str(aucALL_SVM))\n",
    "plt.plot(fprPMP_SVM,tprPMP_SVM,label=\"AUC=\"+str(aucPMP_SVM))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC curves SVM')\n",
    "plt.legend(loc=4)\n",
    "plt.savefig('ROC_svm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(fprPMP,tprPMP,label=\"AUC_PMP=\"+str(aucPMP))\n",
    "plt.plot(fprPTS,tprPTS,label=\"AUC_PTS=\"+str(aucPTS))\n",
    "plt.plot(fprGS,tprGS,label=\"AUC_Games=\"+str(aucGS))\n",
    "plt.plot(fprMP,tprMP,label=\"AUC_MP=\"+str(aucMP))\n",
    "plt.plot(fprALL,tprALL,label=\"AUC_ALL=\"+str(aucALL))\n",
    "plt.plot(fprPTS_SVM,tprPTS_SVM,label=\"AUC_PTS_SVM=\"+str(aucPTS_SVM))\n",
    "plt.plot(fprGS_SVM,tprGS_SVM,label=\"AUC_Games_SVM=\"+str(aucGS_SVM))\n",
    "plt.plot(fprMP_SVM,tprMP_SVM,label=\"AUC_MP_SVM=\"+str(aucMP_SVM))\n",
    "plt.plot(fprALL_SVM,tprALL_SVM,label=\"AUC_ALL_SVM=\"+str(aucALL_SVM))\n",
    "plt.plot(fprPMP_SVM,tprPMP_SVM,label=\"AUC_PMP_SVM=\"+str(aucPMP_SVM))\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC curves ALL')\n",
    "plt.legend(loc=4)\n",
    "plt.savefig('ROC_all.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e3814919d41fe94aab296857dbfcacb89dffc95dcb6d7d1d56fb17f0308132e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
